{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.19"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"2a924f2a-4e2b-4a49-bc95-d281ef098f63","cell_type":"markdown","source":"# Introduction à la bioacoustique","metadata":{}},{"id":"591a76a1-ffa2-4b1b-979a-5400e22b1886","cell_type":"markdown","source":"La bioacoustique, c'est l'étude des signaux sonores produits par les animaux.\nDans cette activité, vous allez manipuler des signaux sonores pour découvrir les principaux concepts de la bioacoustique.","metadata":{}},{"id":"9c6d7caa-a267-4f68-91ab-bbeb873b41fc","cell_type":"markdown","source":"## Etape 1 : L'enregistrement des sons\n\nAvant de pouvoir étudier les signaux sonores produits par les animaux, il faut les enregistrer sur le terrain. Cela nécessite du matériel (microphone, enregistreur, etc) et une logistique plus ou moins complexe (animaux difficiles à approcher, lieux difficiles d'accès, etc.).\n\nDans cette activité, vous allez enregistrer vos propres voix avec le microphone de vos ordinateurs et les étudier avec des outils simples de bioacoustique.\n\n**Exercice**\nVous allez enregistrer vos voix. Rendez-vous sur ce site [ce site](https://online-voice-recorder.com/fr).\n\n![Page d'accueil du site web online-voice-reocrder.com](images/voice_recorder_1.png)\n\nEnregistrez les phonèmes suivants en cinq exemplaires : un long **\"AAAAA\"**, un long **\"EEEEE\"**, un long **\"IIIII\"**, un long **\"OOOOO\"**, un long **\"UUUUU\"**, et un long **\"FFFFF\"**.\n\nIl vous faut cinq exemplaires de chaque son. Essayez de produire des sons de deux secondes, et laissez un peu de silence avant et après vos voix.\n\nPour aller plus vite, vous pouvez faire un long enregistrement où vous prononcez chaque son une fois, puis enregistrer chaque son individuellement en déplaçant les bornes bleues de l'intervale à l'écran.\n\n![Apparence du site web online-voice-recorder.com après un enregistrement](images/voice_recorder_2.png)\n\nRenommez vos fichers avec le format suivant : **SON_NOM_NUMERO** (par exemple, \"AAAAA_BENTI_3.mp3\").\nCliquez sur l'icone dossier en haut à gauche de cette page internet (voir capture d'écran ci-dessous), et glissez-déposez vos enregistrements dans le dossier \"enregistrements\".\n\nEnvoyez-moi vos enregistrements par mail (benjamin.benti@protonmail.com) pour que je prépare le bilan de l'activité.\n\n![Localisation des enregistrements locaux dans le notebook](images/depot_enregistrements.png)","metadata":{}},{"id":"790a43e8-bdd8-4f3a-9b3e-2a379e37951c","cell_type":"markdown","source":"## Etape 2 :  La caractérisation des sons.\n\n### Bon, c'est quoi au juste, un son ?\n\nMaintenant que vous avez vos enregistrements, vous allez pouvoir analyser vos voix.\nConcrètement, à quoi ressemblent-elles ?","metadata":{}},{"id":"2c03f47f-9f1b-40cc-a8ef-6784a1bb19ba","cell_type":"code","source":"# Code python pour le prétraitement et l'harmonisation des enregistrements.\n# Vous n'avez pas besoin de regarder les sections de code dans le détail.\n# Si ça vous intéresse ou si vous avez des questions, vous pouvez m'envoyer un mail : benjamin.benti@protonmail.com\n\n%matplotlib inline\n\n# Import des librairies nécessaires pour le traitement audio et la visualisation\nimport pathlib\nimport random as rd\nimport numpy as np\nimport pandas as pd\nimport librosa as lib\nimport soundfile as sf\nimport matplotlib.pyplot as plt\nimport scipy.signal as sig\nimport ipywidgets as widgets\n\nfrom matplotlib.patches import Ellipse\nimport matplotlib.transforms as transforms\n\ndef get_preprocess_audiofiles(audio_folder):\n    \"\"\"\n    Explore audio-folder and pre-process audio recordings within.\n    Return pandas.DataFrame with name and sound type (from file name) and preprocessed sound\n    \"\"\"\n    # Récupérer la liste des fichiers.\n    if isinstance(audio_folder, str):\n        audio_folder = pathlib.Path(audio_folder)\n    file_list = [f for f in audio_folder.glob(\"*.mp3\")]\n\n    # Prétraitement des enregistrements : filtre bande-bassante entre 50 et 4000 Hz, downsampling à 8000 Hz, harmonisation.\n    df = pd.DataFrame(columns=['ind', 'type', 'sound'], dtype=object)\n    for i, f in enumerate(file_list):\n        # Charger l'enregistrement.\n        y, sr = sf.read(f)\n\n        # Construction d'un filtre bande-passante entre 50 Hz et 4000 Hz.\n        sos = sig.butter(4, (50, 4000), btype=\"bp\", output=\"sos\", fs=sr)\n        # Filtrer les enregistrements.\n        y_filt = sig.sosfilt(sos, y, axis=0)\n\n        # Harmoniser la fréquence d'échantillonage de tous les enregistrements à 8000 Hz.\n        y_ds = sig.decimate(y_filt, round(sr/8000), axis=0)\n        \n        # Harmoniser l'amplitude des enregistrements.\n        norm = np.max(np.abs(y_ds))\n        y_harm = y_ds / norm\n        \n        # Stocker les enregistrements prétraités dans la base de données.\n        fn = str(f)\n        type = fn.split('/')[-1].split('_')[0]\n        ind = fn.split('/')[-1].split('_')[1]\n        df.loc[i, 'ind'] = ind\n        df.loc[i, 'type'] = type\n        df.loc[i, 'sound'] = y_harm\n\n    return df\n\ndata = get_preprocess_audiofiles(pathlib.Path('enregistrements'))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"070b33b8-9495-40e1-8f8a-63c6bca8f8a5","cell_type":"code","source":"# Code python pour la visualisation des enregistrements.\nfrom IPython.display import display\n\ndef waveform_selecttime(y, sr, xlimits=(0, 2.5)):\n    fig = plt.figure()\n    ax = fig.add_subplot()\n    ax.plot([i/sr for i in range(len(y))], y)\n    ax.set_xlabel('Time (s)')\n    ax.set_ylabel('Amplitude (u. a.)')\n    ax.set_xlim(xlimits)\n    plt.show()\n\ny = rd.choice(data.sound)  # Choisir un enregistrement au hasard.\n\nxlimits=widgets.FloatRangeSlider(min=0, max=3, step=0.001, value=(0, 2.5))\nout = widgets.interactive_output(waveform_selecttime, {'y': widgets.fixed(y),\n                                                       'sr': widgets.fixed(8000),\n                                                       'xlimits': xlimits})\nwidgets.VBox([xlimits, out])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b927a58b-369a-4578-9a24-5ebcbeb680c0","cell_type":"markdown","source":"Un son, c'est un ensemble de vibrations de l'air : des fluctuations de pression de différentes fréquences et de différentes amplitudes.\n\nQuand on enregistre un son, on obtient une forme d'onde, qui représente ces fluctuations au cours du temps. C'est un format plutôt obscur, il est difficile d'en extraire directement des informations.","metadata":{}},{"id":"8ef9546a-1166-452a-b277-30df0a83b757","cell_type":"code","source":"# Code python - mini-quizz sur les formes d'onde.\n\n# Choisir des sons au hasard.\nson1 = rd.choice(list(set(data.type)))\nsame = True\nwhile same:\n    son2 = rd.choice(list(set(data.type)))\n    same = (son2 == son1)\n\nex1 = rd.choice(data.loc[data.type==son1].index)\nex2 = rd.choice(data.loc[data.type==son2].index)\nsame = True\nwhile same:\n    ex3 = rd.choice(pd.concat((data.loc[data.type==son1], data.loc[data.type==son2])).index)\n    same = (ex3 == ex1 or ex3 == ex2)\n\n# Construire la figure.\nfig = plt.figure(figsize=(15, 5))\nax1 = fig.add_subplot(131)\nax2 = fig.add_subplot(133)\nax3 = fig.add_subplot(132)\n\ny1 = data.loc[ex1, 'sound']\nax1.plot([i/8000 for i in range(len(y1))], y1)\nax1.set_xlabel('Time (s)')\nax1.set_ylabel('Amplitude (a.u.)')\ny2 = data.loc[ex2, 'sound']\nax2.plot([i/8000 for i in range(len(y2))], y2)\nax2.set_xlabel('Time (s)')\nax2.set_ylabel('Amplitude (a.u.)')\ny3 = data.loc[ex3, 'sound']\nax3.plot([i/8000 for i in range(len(y3))], y3)\nax3.set_xlabel('Time (s)')\nax3.set_ylabel('Amplitude (a.u.)')\n\nax1.set_title('Son 1 : {}'.format(data.loc[ex1, 'type']))\nax2.set_title('Son 2 : {}'.format(data.loc[ex2, 'type']))\nax3.set_title('Mini-quizz : quel est ce son ?')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"9df98e69-1f2e-4f5d-ad56-af3eb4044800","cell_type":"code","source":"# Résultat du quizz.\nprint('Le son mystère était...')\nprint('drum rolls...')\nprint(data.loc[ex3, \"type\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d9eac8be-4b2d-4e42-9575-1d2d15eade3d","cell_type":"markdown","source":"### Un outil magique pour visualiser et analyser les sons : le **spectrogramme**\n\nOn a vu qu'un son est un ensemble de fluctuations de pression à différentes amplitudes et à différentes fréquences. Il est très difficile d'évaluer ces fréquences et ces amplitudes en regardant la forme d'onde.\n\nEn bioacoustique, l'outil principal que l'on utilise pour mieux caractériser les sons, c'est le **spectrogramme**. C'est une transformation mathématique des sons qui permet de voir la composition en fréquences d'un son.","metadata":{}},{"id":"8ca24172-90a4-4990-b9ad-2629e9b898a4","cell_type":"code","source":"# Code python pour le calcul et la visualisation des spectrogrammes.\n\ndef custom_spectro(signal, nfft=1024, ovlp=0.5, win='hann'):\n    \"\"\"\n    Computes the spectrogram of a signal using the input parameters.\n    \"\"\"\n    wind = sig.get_window(win, nfft)\n    S = lib.stft(signal, n_fft=nfft, hop_length=round(nfft*ovlp), window=wind)\n    return S\n\ndef plot_spectro(S, sr, nfft, ovlp, fig, ax, cmap='viridis'):\n    \"\"\"\n    Plots a spectrogram.\n    \"\"\"\n    img = lib.display.specshow(lib.amplitude_to_db(np.abs(S), ref=np.max),\n                               sr=sr, n_fft=nfft, hop_length=round(nfft*ovlp),\n                               ax=ax, y_axis='linear', x_axis='time', cmap=\"viridis\"\n                               )    \n    return fig, ax\n\n# Construire le spectrogramme du son du quizz précédent.\nS = custom_spectro(data.loc[ex3, 'sound'])\nfig = plt.figure()\nax = fig.add_subplot()\nplot_spectro(S, 8000, 1024, 0.5, fig, ax)\nax.set_xlabel('Time (s)')\nax.set_ylabel('Frequency (Hz)')\nax.set_title(\"Spectrogramme d'un {}\".format(data.loc[ex3, 'type']))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f83804e3-b76e-4cd6-82be-19d1abbb6ca8","cell_type":"markdown","source":"Dans les sons animaux, la distribution des fréquences n'est pas aléatoire.","metadata":{}},{"id":"d70996c5-1881-4d76-abad-fa939a5a600a","cell_type":"code","source":"# Code python pour l'analyse de la distribution des fréquences.\n\ndef magnitude_lines(y, sr, F0, xmax=4000, fig=None, ax=None):\n    if fig is None:\n        fig = plt.figure()\n    if ax is None:\n        ax = fig.add_subplot()\n    ax.magnitude_spectrum(y, Fs=8000)\n    for i in range(1, 100):\n        if F0*i <= 4000:\n            ax.axvline(F0*i, color='black')\n    ax.set_xlim(0, xmax)\n    plt.show()\n\nF0 = widgets.IntSlider(description='F0', min=0, max=300, step=1, value=0)\nxmax = widgets.IntSlider(description='Fmax', min=500, max=4000, step=500, value=4000)\nout = widgets.interactive_output(magnitude_lines, {'y': widgets.fixed(data.loc[ex3, 'sound']),\n                                                   'sr': widgets.fixed(8000),\n                                                   'F0': F0,\n                                                   'xmax': xmax\n                                                   }\n                                )\nwidgets.VBox([widgets.HBox([F0, xmax]), out])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c4782c0e-94b9-4434-b8c3-eaf435fb1b52","cell_type":"markdown","source":"### A vous de jouer !!\n\nUtilisez le code de la cellule suivante pour mesurer, pour chacun de vos enregistrements :\n- la fréquence fondamentale **F0**: utilisez le défilement pour aligner les lignes verticales avec les pics de magnitude sur le graphique de droite. Faites glisser le marqueur de droite pour zoomer et mieux aligner les lignes sur les pics de fréquence.\n- la fréquence d'intensité maximale **Fmax**: elle sera indiquée sous les graphiques.\n\nNotez les paramètres acoustiques de votre voix dans un fichier CSV (vous pouvez faire un tableur avec Excel ou LibrOffice et l'enregistrer au format CSV avec l'option \"Fichier -> Enregistrer sous...\").\nLes colonnes de votre tableau doivent s'appeler : \n- **NOM** -> votre nom\n- **F_G_X** -> votre genre, si vous souhaitez l'indiquer\n- **type_de_son** -> le phonème prononcé, en majuscules avec 5 lettres (ex. \"AAAAA\")\n- **numero** -> l'exemplaire du son, de 1 à 5\n- **F0** -> la valeur de la fréquence fondamentale\n- **Fmax** -> la valeur de la fréquence maximale.\n","metadata":{}},{"id":"57ef0a56-343d-422d-858c-e4d0637c7d60","cell_type":"code","source":"# Code python pour la mesure des paramètres acoustiques de vos voix.\n\n# Mise à jour de la base de données avec vos enregistrements.\naudio_folder = pathlib.Path('enregistrements')\ndata = get_preprocess_audiofiles(audio_folder)\n\n# Widgets avec menu déroulant pour sélectionner l'enregistrement.\nliste_noms = list(set(data.ind))\nnom = widgets.Dropdown(options=liste_noms, value=liste_noms[0], description='Nom :')\nliste_sons = list(set(data.type))\nson = widgets.Dropdown(options=liste_sons, value=liste_sons[0], description='Type de son :')\nliste_numeros = [i+1 for i in range(5)]\nnumero = widgets.Dropdown(options=liste_numeros, value=liste_numeros[0], description='n° :')\n\n# Widgets sliders pour la fréquence fondamentale.\nF0 = widgets.IntSlider(description='F0 :', min=0, max=300, step=1, value=0)\nxmax = widgets.IntSlider(description='Fmax :', min=500, max=4000, step=500, value=4000)\n\ndef get_acoustic_features(ind, soundtype, nb, F0, xmax, data=data):\n    \"\"\"\n    Get sound exemplar nb for individual ind and vowel soundtype.\n    Plots spectrogram on the left and magnitude spectrum + lines on the right.\n    Prints Fmax in bottom.\n    \"\"\"\n    # Get sound.\n    y = data.loc[data.ind==ind].loc[data.type==soundtype].iloc[nb-1].sound\n\n    # Prepare figure.\n    fig,(ax1, ax2) = plt.subplots(1,2, figsize=(20, 7))\n\n    # Plot spectrogram.\n    S = custom_spectro(y)\n    plot_spectro(S, 8000, 1024, 0.5, fig, ax1)\n    ax1.set_xlabel('Time (s)')\n    ax2.set_ylabel('Frequency (Hz)')\n    ax2.set_title(\"Spectrogram\")\n    \n    # Mesure la fréquence fondamentale.\n    magnitude_lines(y, sr=8000, F0=F0, xmax=xmax, fig=fig, ax=ax2)\n\n    plt.show()\n\nout = widgets.interactive_output(get_acoustic_features, {'ind': nom, 'soundtype': son, 'nb': numero,\n                                                         'F0': F0, 'xmax': xmax\n                                                          }\n                                 )\n\ndef get_fmax(ind, soundtype, nb):\n    \"\"\"Get Fmax from sound recording\"\"\"\n    # Get sound.\n    y = data.loc[data.ind==ind].loc[data.type==soundtype].iloc[nb-1].sound\n    \n    # Mesurer la fréquence maximale.\n    s, f, l = plt.magnitude_spectrum(y, Fs=8000)\n    plt.close()\n    print('La fréquence maximale de ce son est {} Hz'.format(round(f[np.argmax(s)])))\n\nout2 = widgets.interactive_output(get_fmax, {'ind': nom, 'soundtype': son, 'nb': numero})\n\n\nwidgets.VBox([widgets.HBox([nom, son, numero]), widgets.HBox([F0, xmax]), out, out2])\n","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"id":"c90b41d7-ad3d-49df-8567-bde03a503566","cell_type":"markdown","source":"#### Etape 3 : Analyser les variations sonores\n\nMaintenant que nous avons :\n1. Enregistré des sons et\n2. Mesuré des paramètres acoustiques sur ces enregistrements,\n\nnous pouvons procéder à des comparaisons intra- et inter-individuelles pour répondre à des questions biologiques.","metadata":{}},{"id":"1c2ab925-5a05-4bbd-8b18-b95cb074e326","cell_type":"markdown","source":"### Analyse de vos enregistrements","metadata":{}},{"id":"0c364e71-222c-45f8-be94-f91a05fd0db6","cell_type":"code","source":"#  Ouvrir le tableau comprenant les mesures pour l'ensemble des enregistrements.\ntab = pd.read_csv('mesures/TOTAL_mesures.csv')\n\ndef plot_acoustic_features(individuals, sounds, col, tab=tab):\n    \"\"\"\n    Plot F0 and Fmax for all soundtypes and all inds, mark by individual and color by sound type.\n    \"\"\"\n\n    # Prepare figure.\n    fig = plt.figure(figsize=(10, 10))\n    ax = fig.add_subplot()\n    colorset = [\"#1b9e77\", \"#d95f02\", \"#7570b3\", \"#e7298a\", \"#66a61e\", \"#e6ab02\", \"#a6761d\", \"#666666\", '#000000']\n    markerset = [\"o\", \"+\", \"s\", \"d\", \"v\", 'x', '8', 'p','^']\n    \n    if col == 'sons':  # Color by sound types.\n        for i, elt in enumerate(sounds):\n            tmp = tab.loc[tab.type_de_son==elt]\n            for j, k in enumerate(individuals):\n                tmp2 = tmp.loc[tmp.NOM==k]\n                ax.plot(tmp2.F0, tmp2.Fmax, color=colorset[i], marker=markerset[j], linewidth=0, label='{}-{}'.format(elt, k), markersize=10, markeredgewidth=2.5)\n    elif col == 'individus':  # Color by individuals.\n        for i, elt in enumerate(individuals):\n            tmp = tab.loc[tab.NOM==elt]\n            for j, k in enumerate(sounds):\n                tmp2 = tmp.loc[tmp.type_de_son==k]\n                ax.plot(tmp2.F0, tmp2.Fmax, color=colorset[i], marker=markerset[j], linewidth=0, label='{}-{}'.format(elt, k), markersize=10, markeredgewidth=2.5)\n    ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n    ax.set_xlabel('Fréquence fondamentale (Hz)')\n    ax.set_ylabel('Fréquence maximale (Hz)')\n    return fig, ax","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"8f831bd2-f415-4cdb-86ea-bfd8855ec548","cell_type":"code","source":"# Code pour représenter les mesures réalisées sur les différents types de sons.\n\n# Widgets à checker pour sélectionner les individus à indiquer à l'écran.\nindividus = [widgets.Checkbox(value=False, description=nom) for nom in list(set(tab.NOM))]\nout_inds = widgets.VBox(children=individus)\n\n# Widgets à checker pour inclure les différents types de sons.\nsons = [widgets.Checkbox(value=False, description=son) for son in list(set(tab.type_de_son))]\nout_sons = widgets.VBox(children=sons)\n\n# Widget avec menu déroulant pour sélectionner le groupement pour la coloration.\ncoloring = widgets.Dropdown(options=['individus', 'sons'], value='sons', description='Colorer par :')\n\nparams = widgets.HBox([out_inds, out_sons, coloring])\ndisplay(params)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6d7ea04c-303d-4a3a-bdaf-41c851f9ed3f","cell_type":"code","source":"selected_inds = []\nfor i in range(len(individus)):\n    if individus[i].value == True:\n        selected_inds.append(str(individus[i].description))\n\nselected_sounds = []\nfor i in range(len(sons)):\n    if sons[i].value == True:\n        selected_sounds.append(str(sons[i].description))\n\nselected_col = coloring.value\n\nfig, ax = plot_acoustic_features(selected_inds, selected_sounds, selected_col, tab=tab)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}