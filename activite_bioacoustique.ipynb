{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a924f2a-4e2b-4a49-bc95-d281ef098f63",
   "metadata": {},
   "source": [
    "# Introduction à la bioacoustique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591a76a1-ffa2-4b1b-979a-5400e22b1886",
   "metadata": {},
   "source": [
    "La bioacoustique, c'est l'étude des signaux sonores produits par les animaux.\n",
    "Dans cette activité, vous allez manipuler des signaux sonores pour découvrir les principaux concepts de la bioacoustique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d7caa-a267-4f68-91ab-bbeb873b41fc",
   "metadata": {},
   "source": [
    "## Etape 1 : L'enregistrement des sons\n",
    "\n",
    "Avant de pouvoir étudier les signaux sonores produits par les animaux, il faut les enregistrer sur le terrain. Cela nécessite du matériel (microphone, enregistreur, etc) et une logistique plus ou moins complexe (animaux difficiles à approcher, lieux difficiles d'accès, etc.).\n",
    "\n",
    "Dans cette activité, vous allez enregistrer vos propres voix avec le microphone de vos ordinateurs et les étudier avec des outils simples de bioacoustique.\n",
    "\n",
    "**Exercice**\n",
    "Vous allez enregistrer vos voix. Rendez-vous sur ce site [ce site](https://online-voice-recorder.com/fr).\n",
    "\n",
    "![Page d'accueil du site web online-voice-reocrder.com](images/voice_recorder_1.png)\n",
    "\n",
    "Enregistrez les phonèmes suivants en cinq exemplaires : un long **\"AAAAA\"**, un long **\"EEEEE\"**, un long **\"IIIII\"**, un long **\"OOOOO\"**, un long **\"UUUUU\"**, et un long **\"FFFFF\"**.\n",
    "\n",
    "Il vous faut cinq exemplaires de chaque son. Essayez de produire des sons de deux secondes, et laissez un peu de silence avant et après vos voix.\n",
    "\n",
    "Pour aller plus vite, vous pouvez faire un long enregistrement où vous prononcez chaque son une fois, puis enregistrer chaque son individuellement en déplaçant les bornes bleues de l'intervale à l'écran.\n",
    "\n",
    "![Apparence du site web online-voice-recorder.com après un enregistrement](images/voice_recorder_2.png)\n",
    "\n",
    "Renommez vos fichers avec le format suivant : **SON_NOM_NUMERO** (par exemple, \"AAAAA_BENTI_3.mp3\"). Cliquez sur l'icone dossier en haut à gauche de cette page internet, et glissez-déposez vos enregistrements dans le dossier \"enregistrements\".\n",
    "\n",
    "Envoyez-moi vos enregistrements par mail (benjamin.benti@protonmail.com) pour que je prépare le bilan de l'activité.\n",
    "\n",
    "![Localisation des enregistrements locaux dans le notebook](images/depot_enregistrements.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790a43e8-bdd8-4f3a-9b3e-2a379e37951c",
   "metadata": {},
   "source": [
    "## Etape 2 :  La caractérisation des sons.\n",
    "\n",
    "### Bon, c'est quoi au juste, un son ?\n",
    "\n",
    "Maintenant que vous avez vos enregistrements, vous allez pouvoir analyser vos voix.\n",
    "Concrètement, à quoi ressemblent-elles ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c03f47f-9f1b-40cc-a8ef-6784a1bb19ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code python pour le prétraitement et l'harmonisation des enregistrements.\n",
    "# Vous n'avez pas besoin de regarder les sections de code dans le détail.\n",
    "# Si ça vous intéresse ou si vous avez des questions, vous pouvez m'envoyer un mail : benjamin.benti@protonmail.com\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Import des librairies nécessaires pour le traitement audio et la visualisation\n",
    "import pathlib\n",
    "import random as rd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa as lib\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as sig\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Récupérer la liste des fichiers.\n",
    "audio_folder = pathlib.Path('enregistrements')\n",
    "file_list = [f for f in audio_folder.glob(\"*\")]\n",
    "\n",
    "# Prétraitement des enregistrements : filtre bande-bassante entre 50 et 4000 Hz, downsampling à 8000 Hz, harmonisation.\n",
    "df = pd.DataFrame(columns=['ind', 'type', 'sound'], dtype=object)\n",
    "for i, f in enumerate(file_list):\n",
    "    # Charger l'enregistrement.\n",
    "    y, sr = sf.read(f)\n",
    "    \n",
    "    # Construction d'un filtre bande-passante entre 50 Hz et 4000 Hz.\n",
    "    sos = sig.butter(4, (50, 4000), btype=\"bp\", output=\"sos\", fs=sr)\n",
    "    # Filtrer les enregistrements.\n",
    "    y_filt = sig.sosfilt(sos, y, axis=0)\n",
    "    \n",
    "    # Harmoniser la fréquence d'échantillonage de tous les enregistrements à 8000 Hz.\n",
    "    y_ds = sig.decimate(y_filt, round(sr/8000), axis=0)\n",
    "    \n",
    "    # Harmoniser l'amplitude des enregistrements.\n",
    "    norm = np.max(np.abs(y_ds))\n",
    "    y_harm = y_ds / norm\n",
    "\n",
    "    # Stocker les enregistrements prétraités dans la base de données.\n",
    "    fn = str(f)\n",
    "    type = fn.split('/')[-1].split('_')[0]\n",
    "    ind = fn.split('/')[-1].split('_')[1]\n",
    "    df.loc[i, 'ind'] = ind\n",
    "    df.loc[i, 'type'] = type\n",
    "    df.loc[i, 'sound'] = y_harm\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070b33b8-9495-40e1-8f8a-63c6bca8f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code python pour la visualisation des enregistrements.\n",
    "from IPython.display import display\n",
    "\n",
    "def waveform_selecttime(y, sr, xlimits=(0, 2.5)):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot()\n",
    "    ax.plot([i/sr for i in range(len(y))], y)\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Amplitude (u. a.)')\n",
    "    ax.set_xlim(xlimits)\n",
    "    plt.show()\n",
    "\n",
    "y = rd.choice(df.sound)  # Choisir un enregistrement au hasard.\n",
    "\n",
    "xlimits=widgets.FloatRangeSlider(min=0, max=3, step=0.001, value=(0, 2.5))\n",
    "out = widgets.interactive_output(waveform_selecttime, {'y': widgets.fixed(y),\n",
    "                                                       'sr': widgets.fixed(8000),\n",
    "                                                       'xlimits': xlimits})\n",
    "widgets.VBox([xlimits, out])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b927a58b-369a-4578-9a24-5ebcbeb680c0",
   "metadata": {},
   "source": [
    "Un son, c'est un ensemble de vibrations de l'air : des fluctuations de pression de différentes fréquences et de différentes amplitudes.\n",
    "\n",
    "Quand on enregistre un son, on obtient une forme d'onde, qui représente ces fluctuations au cours du temps. C'est un format plutôt obscur, il est difficile d'en extraire directement des informations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef9546a-1166-452a-b277-30df0a83b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code python - mini-quizz sur les formes d'onde.\n",
    "\n",
    "# Choisir des sons au hasard.\n",
    "son1 = rd.choice(list(set(df.type)))\n",
    "same = True\n",
    "while same:\n",
    "    son2 = rd.choice(list(set(df.type)))\n",
    "    same = (son2 == son1)\n",
    "\n",
    "ex1 = rd.choice(df.loc[df.type==son1].index)\n",
    "ex2 = rd.choice(df.loc[df.type==son2].index)\n",
    "same = True\n",
    "while same:\n",
    "    ex3 = rd.choice(pd.concat((df.loc[df.type==son1], df.loc[df.type==son2])).index)\n",
    "    same = (ex3 == ex1 or ex3 == ex2)\n",
    "\n",
    "# Construire la figure.\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax2 = fig.add_subplot(133)\n",
    "ax3 = fig.add_subplot(132)\n",
    "\n",
    "y1 = df.loc[ex1, 'sound']\n",
    "ax1.plot([i/8000 for i in range(len(y1))], y1)\n",
    "ax1.set_xlabel('Time (s)')\n",
    "ax1.set_ylabel('Amplitude (a.u.)')\n",
    "y2 = df.loc[ex2, 'sound']\n",
    "ax2.plot([i/8000 for i in range(len(y2))], y2)\n",
    "ax2.set_xlabel('Time (s)')\n",
    "ax2.set_ylabel('Amplitude (a.u.)')\n",
    "y3 = df.loc[ex3, 'sound']\n",
    "ax3.plot([i/8000 for i in range(len(y3))], y3)\n",
    "ax3.set_xlabel('Time (s)')\n",
    "ax3.set_ylabel('Amplitude (a.u.)')\n",
    "\n",
    "ax1.set_title('Son 1 : {}'.format(df.loc[ex1, 'type']))\n",
    "ax2.set_title('Son 2 : {}'.format(df.loc[ex2, 'type']))\n",
    "ax3.set_title('Mini-quizz : quel est ce son ?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df98e69-1f2e-4f5d-ad56-af3eb4044800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Résultat du quizz.\n",
    "print('Le son mystère était...')\n",
    "print('drum rolls...')\n",
    "print(df.loc[ex3, \"type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eac8be-4b2d-4e42-9575-1d2d15eade3d",
   "metadata": {},
   "source": [
    "### Un outil magique pour visualiser et analyser les sons : le **spectrogramme**\n",
    "\n",
    "On a vu qu'un son est un ensemble de fluctuations de pression à différentes amplitudes et à différentes fréquences. Il est très difficile d'évaluer ces fréquences et ces amplitudes en regardant la forme d'onde.\n",
    "\n",
    "En bioacoustique, l'outil principal que l'on utilise pour mieux caractériser les sons, c'est le **spectrogramme**. C'est une transformation mathématique des sons qui permet de voir la composition en fréquences d'un son."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca24172-90a4-4990-b9ad-2629e9b898a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code python pour le calcul et la visualisation des spectrogrammes.\n",
    "\n",
    "def custom_spectro(signal, nfft=1024, ovlp=0.5, win='hann'):\n",
    "    \"\"\"\n",
    "    Computes the spectrogram of a signal using the input parameters.\n",
    "    \"\"\"\n",
    "    wind = sig.get_window(win, nfft)\n",
    "    S = lib.stft(signal, n_fft=nfft, hop_length=round(nfft*ovlp), window=wind)\n",
    "    return S\n",
    "\n",
    "def plot_spectro(S, sr, nfft, ovlp, fig, ax, cmap='viridis'):\n",
    "    \"\"\"\n",
    "    Plots a spectrogram.\n",
    "    \"\"\"\n",
    "    img = lib.display.specshow(lib.amplitude_to_db(np.abs(S), ref=np.max),\n",
    "                               sr=sr, n_fft=nfft, hop_length=round(nfft*ovlp),\n",
    "                               ax=ax, y_axis='linear', x_axis='time', cmap=\"viridis\"\n",
    "                               )    \n",
    "    return fig, ax\n",
    "\n",
    "# Construire le spectrogramme du son du quizz précédent.\n",
    "S = custom_spectro(df.loc[ex3, 'sound'])\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "plot_spectro(S, 8000, 1024, 0.5, fig, ax)\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Frequency (Hz)')\n",
    "ax.set_title(\"Spectrogramme d'un {}\".format(df.loc[ex3, 'type']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83804e3-b76e-4cd6-82be-19d1abbb6ca8",
   "metadata": {},
   "source": [
    "Dans les sons animaux, la distribution des fréquences n'est pas aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70996c5-1881-4d76-abad-fa939a5a600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code python pour l'analyse de la distribution des fréquences.\n",
    "\n",
    "def magnitude_lines(y, sr, F0, xmax=4000):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot()\n",
    "    ax.magnitude_spectrum(y[int(1*8000):2*8000], Fs=8000)\n",
    "    for i in range(1, 1000):\n",
    "        if F0*i <= 4000:\n",
    "            ax.axvline(F0*i, color='black')\n",
    "    ax.set_xlim(0, xmax)\n",
    "    plt.show()\n",
    "\n",
    "F0 = widgets.IntSlider(description='F0', min=0, max=500, step=1, value=100)\n",
    "xmax = widgets.IntSlider(description='Fmax', min=500, max=4000, step=500, value=4000)\n",
    "out = widgets.interactive_output(magnitude_lines, {'y': widgets.fixed(df.loc[ex3, 'sound']),\n",
    "                                                   'sr': widgets.fixed(8000),\n",
    "                                                   'F0': F0,\n",
    "                                                   'xmax': xmax\n",
    "                                                   }\n",
    "                                )\n",
    "widgets.VBox([widgets.HBox([F0, xmax]), out])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4782c0e-94b9-4434-b8c3-eaf435fb1b52",
   "metadata": {},
   "source": [
    "### A vous de jouer !!\n",
    "\n",
    "Utilisez le code de la cellule suivante pour mesurer, pour chacun de vos enregistrements :\n",
    "- la fréquence fondamentale **F0**\n",
    "- la fréquence d'intensité maximale **Fmax**\n",
    "\n",
    "Notez vos mesures dans un fichier excel ("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cae295-4e93-43c6-97df-ed2ae601e7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifiez les lignes suivantes pour sélectionner votre enregistrement.\n",
    "nom = 'BENTI'\n",
    "son = 'UUUUU'\n",
    "numero = 1\n",
    "\n",
    "y = df.loc[df.ind==nom].loc[df.type==son].iloc[numero-1].sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ffb056-c55c-40e8-a9d1-f76262254175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesure la fréquence fondamentale.\n",
    "F0 = widgets.IntSlider(description='F0', min=0, max=500, step=1, value=100)\n",
    "xmax = widgets.IntSlider(description='Fmax', min=500, max=4000, step=500, value=4000)\n",
    "out = widgets.interactive_output(magnitude_lines, {'y': widgets.fixed(y),\n",
    "                                                   'sr': widgets.fixed(8000),\n",
    "                                                   'F0': F0,\n",
    "                                                   'xmax': xmax\n",
    "                                                   }\n",
    "                                )\n",
    "widgets.VBox([widgets.HBox([F0, xmax]), out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa489a94-2473-46b4-90b9-cb92d9fe6469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesurer la fréquence maximale.\n",
    "s, f, l = plt.magnitude_spectrum(y[8000:2*8000], Fs=8000)\n",
    "plt.close()\n",
    "print('La fréquence maximale de ce son est {} Hz'.format(round(f[np.argmax(s)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90b41d7-ad3d-49df-8567-bde03a503566",
   "metadata": {},
   "source": [
    "#### Etape 3 : Analyser les variations sonores\n",
    "\n",
    "Maintenant que nous avons :\n",
    "1. Enregistré des sons et\n",
    "2. Mesuré des paramètres acoustiques sur ces enregistrements,\n",
    "\n",
    "nous pouvons procéder à des comparaisons intra- et inter-individuelles pour répondre à des questions biologiques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6f7e4d-dc96-4c30-916c-b0ed971c0ee5",
   "metadata": {},
   "source": [
    "### 1ère question : pouvons-nous décrire un mini-répertoire vocal pour l'être humain ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f831bd2-f415-4cdb-86ea-bfd8855ec548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code pour représenter les mesures réalisées sur les différents types de sons.\n",
    "\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "\n",
    "tab = pd.read_csv('mesures/BENTI_mesures.csv')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "colorset = [\"#000000\", \"#1b9e77\", \"#d95f02\", \"#7570b3\", \"#e7298a\", \"#66a61e\"]\n",
    "markerset = [\"o\", \"+\", \"s\", \"d\", \"v\", 'x']\n",
    "for i, elt in enumerate(list(set(tab.type_de_son))):\n",
    "    tmp = tab.loc[tab.type_de_son==elt]\n",
    "    ax.plot(tmp.F0, tmp.Fmax, color=colorset[i], marker=markerset[i], linewidth=0, alpha=0.5)\n",
    "    ax.legend(labels = list(set(tab.type_de_son)))\n",
    "\n",
    "# Add ellipse.\n",
    "for i, elt in enumerate(list(set(tab.type_de_son))):\n",
    "    tmp = tab.loc[tab.type_de_son==elt]\n",
    "    cov = np.cov(tmp.F0, tmp.Fmax)\n",
    "    if cov[0, 0] != 0 and cov[1, 1] != 0:\n",
    "        pearson = cov[0, 1]/np.sqrt(cov[0, 0] * cov[1, 1])\n",
    "        # Get the ellipse radius.\n",
    "        radius_x = np.sqrt(1 + pearson)\n",
    "        radius_y = np.sqrt(1 - pearson)\n",
    "        ellipse = Ellipse((0, 0),\n",
    "                          width=radius_x * 2,\n",
    "                          height=radius_y * 2,\n",
    "                          facecolor=colorset[i],\n",
    "                          alpha=0.3,\n",
    "                          edgecolor=colorset[i],\n",
    "                          linewidth=2\n",
    "                          )\n",
    "        # Scale and center.\n",
    "        scale_x = np.sqrt(cov[0, 0])\n",
    "        scale_y = np.sqrt(cov[1, 1])\n",
    "        # Rotate and scale the ellipse.\n",
    "        transf = transforms.Affine2D() \\\n",
    "                 .rotate_deg(45) \\\n",
    "                 .scale(scale_x, scale_y) \\\n",
    "                 .translate(np.mean(tmp.F0), np.mean(tmp.Fmax))\n",
    "        ellipse.set_transform(transf + ax.transData)\n",
    "        ax.add_patch(ellipse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7ea04c-303d-4a3a-bdaf-41c851f9ed3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code pour représenter les mesures réalisées sur les différents types de sons, excluant les FFFFF.\n",
    "\n",
    "tab = pd.read_csv('mesures/BENTI_mesures.csv')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "colorset = [\"#1b9e77\", \"#d95f02\", \"#000000\", \"#7570b3\", \"#e7298a\", \"#66a61e\"]\n",
    "markerset = [\"o\", \"+\", \"s\", \"d\", \"v\", 'x']\n",
    "\n",
    "lst = list(set(tab.type_de_son))\n",
    "lst.remove('FFFFF')\n",
    "\n",
    "for i, elt in enumerate(list(set(tab.type_de_son))):\n",
    "    if elt == 'FFFFF':\n",
    "        continue\n",
    "    tmp = tab.loc[tab.type_de_son==elt]\n",
    "    ax.plot(tmp.F0, tmp.Fmax, color=colorset[i], marker=markerset[i], linewidth=0, alpha=0.5)\n",
    "    ax.set_xlabel('Fréquence fondamentale (Hz)')\n",
    "    ax.set_ylabel('Fréquence maximale (Hz)')\n",
    "    ax.legend(labels = lst)\n",
    "\n",
    "# Add ellipse.\n",
    "for i, elt in enumerate(list(set(tab.type_de_son))):\n",
    "    if elt == 'FFFFF':\n",
    "        continue\n",
    "    tmp = tab.loc[tab.type_de_son==elt]\n",
    "    cov = np.cov(tmp.F0, tmp.Fmax)\n",
    "    print(elt, cov)\n",
    "    if cov[0, 0] != 0 and cov[1, 1] != 0:\n",
    "        pearson = cov[0, 1]/np.sqrt(cov[0, 0] * cov[1, 1])\n",
    "        # Get the ellipse radius.\n",
    "        radius_x = np.sqrt(1 + pearson)\n",
    "        radius_y = np.sqrt(1 - pearson)\n",
    "        ellipse = Ellipse((0, 0),\n",
    "                          width=radius_x * 2,\n",
    "                          height=radius_y * 2,\n",
    "                          facecolor=colorset[i],\n",
    "                          alpha=0.3,\n",
    "                          edgecolor=colorset[i],\n",
    "                          linewidth=2\n",
    "                          )\n",
    "        # Scale and center.\n",
    "        scale_x = np.sqrt(cov[0, 0])\n",
    "        scale_y = np.sqrt(cov[1, 1])\n",
    "        # Rotate and scale the ellipse.\n",
    "        transf = transforms.Affine2D() \\\n",
    "                 .rotate_deg(45) \\\n",
    "                 .scale(scale_x, scale_y) \\\n",
    "                 .translate(np.mean(tmp.F0), np.mean(tmp.Fmax))\n",
    "        ellipse.set_transform(transf + ax.transData)\n",
    "        ax.add_patch(ellipse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763a07b3-4c1d-47de-a96e-c8a5b9a3084d",
   "metadata": {},
   "source": [
    "## 2ème question: Existe-t-il des différences interindividuelles dans les voix humaines ? Comment les expliquer ?\n",
    "\n",
    "(cf. activité \"Voix des hommes\" au début du TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ffacc0-bd62-4bb5-b73f-603a6009e4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code pour regrouper les mesures faites par différents membres du groupe.\n",
    "\n",
    "#=====> Rentrer les noms des membres du groupe dans la liste.\n",
    "liste_individus = [\"BENTI\", \"LEMAIRE\"]\n",
    "\n",
    "data = pd.DataFrame()\n",
    "for i in liste_individus:\n",
    "    tab = pd.read_csv(\"mesures/{}_mesures.csv\".format(i))\n",
    "    data = pd.concat((data, tab))\n",
    "    data.index = range(data.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6838f51-9ff9-4e48-b5eb-fab32d849633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code pour visualiser les données de tout le groupe.\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "color_set = [\"#000000\", \"#009292\", \"#ff6db6\", \"#490092\", \"#006ddb\",\n",
    "              \"#924900\", \"#004949\", \"#ffb6db\", \"#b66dff\", \"#6db6ff\",\n",
    "              \"#db6d00\"\n",
    "              ]\n",
    "markerset = [\"o\", \"+\", \"s\", \"d\", \"v\", 'x']\n",
    "\n",
    "for i, ind in enumerate(liste_individus):\n",
    "    for j, elt in enumerate(list(set(data.type_de_son))):\n",
    "        tmp = data.loc[data.NOM==ind].loc[data.type_de_son==elt]\n",
    "        ax.plot(tmp.F0, tmp.Fmax, color=colorset[i], marker=markerset[j], linewidth=0)\n",
    "    ax.legend(labels = list(set(data.type_de_son)))\n",
    "    ax.set_xlabel('Fréquence fondamentale (Hz)')\n",
    "    ax.set_ylabel('Fréquence maximale (Hz)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3042d5-7f76-42b9-957a-ae8c0e9b959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code pour visualiser les données de tout le groupe, sans les FFFFF.\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "color_set = [\"#000000\", \"#009292\", \"#ff6db6\", \"#490092\", \"#006ddb\",\n",
    "              \"#924900\", \"#004949\", \"#ffb6db\", \"#b66dff\", \"#6db6ff\",\n",
    "              \"#db6d00\"\n",
    "              ]\n",
    "markerset = [\"o\", \"+\", \"s\", \"d\", \"v\", 'x']\n",
    "\n",
    "for i, ind in enumerate(liste_individus):\n",
    "    for j, elt in enumerate(list(set(data.type_de_son))):\n",
    "        if elt == \"FFFFF\":\n",
    "            continue\n",
    "        tmp = data.loc[data.NOM==ind].loc[data.type_de_son==elt]\n",
    "        ax.plot(tmp.F0, tmp.Fmax, color=colorset[i], marker=markerset[j], linewidth=0)\n",
    "    ax.legend(labels = lst)\n",
    "    ax.set_xlabel('Fréquence fondamentale (Hz)')\n",
    "    ax.set_ylabel('Fréquence maximale (Hz)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cc717f-923f-4c6f-89da-aa11a1ce8e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code pour comparer les mesures réalisées pour un même son par différents membres du groupe.\n",
    "\n",
    "son = 'AAAAA'  # LA IL FAUT REMPLACER PAR LE SON QUI VOUS INTERESSE.\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "color_set = [\"#000000\", \"#009292\", \"#ff6db6\", \"#490092\", \"#006ddb\",\n",
    "              \"#924900\", \"#004949\", \"#ffb6db\", \"#b66dff\", \"#6db6ff\",\n",
    "              \"#db6d00\"\n",
    "              ]\n",
    "markerset = [\"o\", \"+\", \"s\", \"d\", \"v\", 'x', \"^\", \"8\", \"p\", \"*\", \"h\"]\n",
    "\n",
    "for i, ind in enumerate(liste_individus):\n",
    "    tmp = data.loc[data.type_de_son==son].loc[data.NOM==ind]\n",
    "    ax.plot(tmp.F0, tmp.Fmax, color=colorset[i], marker=markerset[i], linewidth=0)\n",
    "    ax.set_xlabel('Fréquence fondamentale (Hz)')\n",
    "    ax.set_ylabel('Fréquence maximale (Hz)')\n",
    "    ax.legend(labels = liste_individus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73404a01-1a17-43ab-bcce-f7b0345c2bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
